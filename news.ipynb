{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scipy in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: numpy in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "Requirement already satisfied: scikit-learn in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from lightgbm)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: tqdm in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting gensim\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/2b/e0/fa6326251692056dc880a64eb22117e03269906ba55a6864864d24ec8b4e/gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 24.2MB 65.7MB/s ta 0:00:011▎                            | 2.5MB 81.7MB/s eta 0:00:0101   34% |███████████                     | 8.3MB 83.6MB/s eta 0:00:01███████████████▌           | 15.5MB 81.1MB/s eta 0:00:01�████      | 19.6MB 100.6MB/s eta 0:00:01�██▋ | 23.1MB 97.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from gensim)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/0b/8e/464b06f5efd26f2dc16ce7bd1662c2f31cadf9104fdbcbf5994674cc3a51/smart_open-2.1.0.tar.gz (116kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 69.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from gensim)\n",
      "Requirement already satisfied: requests in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim)\n",
      "Collecting boto (from smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 58.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting boto3 (from smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/1f/8f/3b55fc90227d56ef75fc36db5fefeed1c2b51a0589715e6ae21db317b99f/boto3-1.14.26-py2.py3-none-any.whl (128kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim)\n",
      "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
      "Collecting s3transfer<0.4.0,>=0.3.0 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 56.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting botocore<1.18.0,>=1.17.26 (from boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/ab/e5/4bf433f4fe4bb193f65c9d8be0b72d31c0ac04a564b787cc0f0929644325/botocore-1.17.26-py2.py3-none-any.whl (6.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.4MB 93.3MB/s ta 0:00:011  8% |██▊                             | 552kB 79.7MB/s eta 0:00:01�█████████| 6.4MB 100.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10 (from botocore<1.18.0,>=1.17.26->boto3->smart-open>=1.8.1->gensim)\n",
      "  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/22/cd/a6aa959dca619918ccb55023b4cb151949c64d4d5d55b3f4ffd7eee0c6e8/docutils-0.15.2-py3-none-any.whl (547kB)\n",
      "\u001b[K    100% |████████████████████████████████| 552kB 38.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ma-user/anaconda3/envs/XGBoost-Sklearn/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.26->boto3->smart-open>=1.8.1->gensim)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Running setup.py bdist_wheel for smart-open ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ma-user/.cache/pip/wheels/00/94/c2/1722b3d5740cca836ba3fc38f17c82f6ca2e4a2e8cde51135f\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 boto3-1.14.26 botocore-1.17.26 docutils-0.15.2 gensim-3.8.3 jmespath-0.10.0 s3transfer-0.3.3 smart-open-2.1.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 20.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm\n",
    "!pip install tqdm\n",
    "!pip install gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "import gensim.models\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_set.csv', sep='\\t')\n",
    "test = pd.read_csv('test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2967 6758 339 2021 1854 3731 4109 3792 4149 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>4464 486 6352 5619 2465 4802 1452 3137 5778 54...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7346 4068 5074 3747 5681 6093 1777 2226 7354 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>7159 948 4866 2109 5520 2490 211 3956 5520 549...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>3646 3055 3055 2490 4659 6065 3370 5814 2465 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>3819 4525 1129 6725 6485 2109 3800 5264 1006 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>307 4780 6811 1580 7539 5886 5486 3433 6644 58...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>26 4270 1866 5977 3523 3764 4464 3659 4853 517...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>2708 2218 5915 4559 886 1241 4819 314 4261 166...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>3654 531 1348 29 4553 6722 1474 5099 7541 307 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>3659 3659 1903 1866 4326 4744 7239 3479 4261 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>6469 1066 1623 1018 3694 4089 3809 4516 6656 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>3772 4269 3433 6122 2035 4531 465 6565 498 358...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>4630 2210 1641 1854 1641 4543 3017 4409 5430 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1103 6835 3433 2107 5165 7543 3598 5229 1946 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>4412 5988 5036 4216 7539 5644 1906 2380 2252 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2400 4411 5968 2612 6920 4464 3659 6250 2799 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>2410 6587 6644 2727 4109 5247 5310 5547 5949 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>3170 3508 4163 2974 1952 4417 4987 5505 4163 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>4269 3772 5445 2289 2109 5410 1991 5589 2986 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>6569 4690 2663 5391 1315 3987 1519 4893 7539 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>3017 505 1070 1036 2621 4480 5117 3772 4786 56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3263 6104 7539 5744 2827 2367 4893 1647 4315 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>3418 1939 220 6886 623 149 1679 3099 1324 7543...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12</td>\n",
       "      <td>314 4261 1667 2810 2334 5176 2376 4646 478 132...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>7154 2592 5562 2828 4559 2376 5780 3650 3203 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3</td>\n",
       "      <td>1965 2717 2728 1951 3744 4831 5698 3915 5099 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>6861 6654 1362 4333 3272 1697 7044 1519 4516 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1141 5915 6178 4842 6725 7261 7408 4671 6846 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>2289 6357 3577 751 2402 3377 5589 4853 7467 51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199970</th>\n",
       "      <td>7</td>\n",
       "      <td>6835 5296 1854 5036 1844 2400 2438 6093 3961 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199971</th>\n",
       "      <td>4</td>\n",
       "      <td>56 4411 5410 1215 3912 1829 6613 1563 4040 125...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199972</th>\n",
       "      <td>0</td>\n",
       "      <td>623 6637 6680 4893 4063 6111 5330 2465 1744 41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199973</th>\n",
       "      <td>0</td>\n",
       "      <td>4923 7449 3055 1116 2289 1736 531 7539 5269 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199974</th>\n",
       "      <td>1</td>\n",
       "      <td>2642 4909 7306 2549 7539 3107 2549 2328 2164 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199975</th>\n",
       "      <td>2</td>\n",
       "      <td>3661 1731 6352 3508 531 4998 5315 851 5530 663...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199976</th>\n",
       "      <td>2</td>\n",
       "      <td>6405 3203 6644 4350 3568 5094 5221 4958 3608 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199977</th>\n",
       "      <td>2</td>\n",
       "      <td>6227 6227 4333 4183 3792 2490 3971 408 671 715...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199978</th>\n",
       "      <td>2</td>\n",
       "      <td>4173 5603 4960 150 2679 2376 5530 5057 669 356...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199979</th>\n",
       "      <td>2</td>\n",
       "      <td>6549 2313 3743 6065 4464 7543 4173 2828 3012 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199980</th>\n",
       "      <td>5</td>\n",
       "      <td>1334 3923 7532 6045 4553 4775 3018 7013 6983 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199981</th>\n",
       "      <td>5</td>\n",
       "      <td>6357 150 4233 23 4811 2334 3317 7010 5282 3971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199982</th>\n",
       "      <td>4</td>\n",
       "      <td>4411 150 5480 307 6973 2364 3648 5370 2380 620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199983</th>\n",
       "      <td>1</td>\n",
       "      <td>847 3809 5385 281 4301 3560 3809 3694 299 6656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199984</th>\n",
       "      <td>0</td>\n",
       "      <td>7544 134 5659 6065 4646 3370 803 469 7047 2415...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199985</th>\n",
       "      <td>0</td>\n",
       "      <td>5057 1859 7449 4659 4543 3976 2465 2515 3329 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>3</td>\n",
       "      <td>141 6956 7528 7495 7354 5681 5530 2112 3000 28...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>2</td>\n",
       "      <td>3000 3148 5139 5977 2490 1308 5498 2289 2614 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>4</td>\n",
       "      <td>517 5620 2986 7539 2255 3915 5445 1460 6587 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>1</td>\n",
       "      <td>3469 3772 3117 4413 2313 3743 1070 2107 2621 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>4</td>\n",
       "      <td>6811 1580 7539 6193 5169 7219 2022 5296 2364 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>2</td>\n",
       "      <td>5511 4893 2115 5192 3934 6256 3554 2457 2282 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199992</th>\n",
       "      <td>0</td>\n",
       "      <td>3479 6662 1913 4641 2465 2465 495 4516 1146 69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>0</td>\n",
       "      <td>1363 4409 2210 3961 5736 2539 3012 2380 5689 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199994</th>\n",
       "      <td>3</td>\n",
       "      <td>1640 5310 2923 913 7109 6992 6722 6337 3982 73...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>2</td>\n",
       "      <td>307 4894 7539 4853 5330 648 6038 4409 3764 603...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>2</td>\n",
       "      <td>3792 2983 355 1070 4464 5050 6298 3782 3130 68...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>11</td>\n",
       "      <td>6811 1580 7539 1252 1899 5139 1386 3870 4124 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>2</td>\n",
       "      <td>6405 3203 6644 983 794 1913 1678 5736 1397 191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>3</td>\n",
       "      <td>4350 3878 3268 1699 6909 5505 2376 2465 6088 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                                               text\n",
       "0           2  2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
       "1          11  4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
       "2           3  7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n",
       "3           2  7159 948 4866 2109 5520 2490 211 3956 5520 549...\n",
       "4           3  3646 3055 3055 2490 4659 6065 3370 5814 2465 5...\n",
       "5           9  3819 4525 1129 6725 6485 2109 3800 5264 1006 4...\n",
       "6           3  307 4780 6811 1580 7539 5886 5486 3433 6644 58...\n",
       "7          10  26 4270 1866 5977 3523 3764 4464 3659 4853 517...\n",
       "8          12  2708 2218 5915 4559 886 1241 4819 314 4261 166...\n",
       "9           3  3654 531 1348 29 4553 6722 1474 5099 7541 307 ...\n",
       "10          0  3659 3659 1903 1866 4326 4744 7239 3479 4261 4...\n",
       "11          7  6469 1066 1623 1018 3694 4089 3809 4516 6656 3...\n",
       "12          4  3772 4269 3433 6122 2035 4531 465 6565 498 358...\n",
       "13          0  4630 2210 1641 1854 1641 4543 3017 4409 5430 6...\n",
       "14          0  1103 6835 3433 2107 5165 7543 3598 5229 1946 2...\n",
       "15          1  4412 5988 5036 4216 7539 5644 1906 2380 2252 6...\n",
       "16          1  2400 4411 5968 2612 6920 4464 3659 6250 2799 5...\n",
       "17          2  2410 6587 6644 2727 4109 5247 5310 5547 5949 7...\n",
       "18          4  3170 3508 4163 2974 1952 4417 4987 5505 4163 2...\n",
       "19          2  4269 3772 5445 2289 2109 5410 1991 5589 2986 1...\n",
       "20          0  6569 4690 2663 5391 1315 3987 1519 4893 7539 3...\n",
       "21          1  3017 505 1070 1036 2621 4480 5117 3772 4786 56...\n",
       "22          2  3263 6104 7539 5744 2827 2367 4893 1647 4315 1...\n",
       "23          2  3418 1939 220 6886 623 149 1679 3099 1324 7543...\n",
       "24         12  314 4261 1667 2810 2334 5176 2376 4646 478 132...\n",
       "25          4  7154 2592 5562 2828 4559 2376 5780 3650 3203 5...\n",
       "26          3  1965 2717 2728 1951 3744 4831 5698 3915 5099 5...\n",
       "27          4  6861 6654 1362 4333 3272 1697 7044 1519 4516 4...\n",
       "28          1  1141 5915 6178 4842 6725 7261 7408 4671 6846 5...\n",
       "29          1  2289 6357 3577 751 2402 3377 5589 4853 7467 51...\n",
       "...       ...                                                ...\n",
       "199970      7  6835 5296 1854 5036 1844 2400 2438 6093 3961 1...\n",
       "199971      4  56 4411 5410 1215 3912 1829 6613 1563 4040 125...\n",
       "199972      0  623 6637 6680 4893 4063 6111 5330 2465 1744 41...\n",
       "199973      0  4923 7449 3055 1116 2289 1736 531 7539 5269 18...\n",
       "199974      1  2642 4909 7306 2549 7539 3107 2549 2328 2164 5...\n",
       "199975      2  3661 1731 6352 3508 531 4998 5315 851 5530 663...\n",
       "199976      2  6405 3203 6644 4350 3568 5094 5221 4958 3608 7...\n",
       "199977      2  6227 6227 4333 4183 3792 2490 3971 408 671 715...\n",
       "199978      2  4173 5603 4960 150 2679 2376 5530 5057 669 356...\n",
       "199979      2  6549 2313 3743 6065 4464 7543 4173 2828 3012 5...\n",
       "199980      5  1334 3923 7532 6045 4553 4775 3018 7013 6983 4...\n",
       "199981      5  6357 150 4233 23 4811 2334 3317 7010 5282 3971...\n",
       "199982      4  4411 150 5480 307 6973 2364 3648 5370 2380 620...\n",
       "199983      1  847 3809 5385 281 4301 3560 3809 3694 299 6656...\n",
       "199984      0  7544 134 5659 6065 4646 3370 803 469 7047 2415...\n",
       "199985      0  5057 1859 7449 4659 4543 3976 2465 2515 3329 2...\n",
       "199986      3  141 6956 7528 7495 7354 5681 5530 2112 3000 28...\n",
       "199987      2  3000 3148 5139 5977 2490 1308 5498 2289 2614 2...\n",
       "199988      4  517 5620 2986 7539 2255 3915 5445 1460 6587 42...\n",
       "199989      1  3469 3772 3117 4413 2313 3743 1070 2107 2621 5...\n",
       "199990      4  6811 1580 7539 6193 5169 7219 2022 5296 2364 4...\n",
       "199991      2  5511 4893 2115 5192 3934 6256 3554 2457 2282 1...\n",
       "199992      0  3479 6662 1913 4641 2465 2465 495 4516 1146 69...\n",
       "199993      0  1363 4409 2210 3961 5736 2539 3012 2380 5689 2...\n",
       "199994      3  1640 5310 2923 913 7109 6992 6722 6337 3982 73...\n",
       "199995      2  307 4894 7539 4853 5330 648 6038 4409 3764 603...\n",
       "199996      2  3792 2983 355 1070 4464 5050 6298 3782 3130 68...\n",
       "199997     11  6811 1580 7539 1252 1899 5139 1386 3870 4124 1...\n",
       "199998      2  6405 3203 6644 983 794 1913 1678 5736 1397 191...\n",
       "199999      3  4350 3878 3268 1699 6909 5505 2376 2465 6088 2...\n",
       "\n",
       "[200000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2967 6758 339 2021 1854 3731 4109 3792 4149 15...\n",
       "1         4464 486 6352 5619 2465 4802 1452 3137 5778 54...\n",
       "2         7346 4068 5074 3747 5681 6093 1777 2226 7354 6...\n",
       "3         7159 948 4866 2109 5520 2490 211 3956 5520 549...\n",
       "4         3646 3055 3055 2490 4659 6065 3370 5814 2465 5...\n",
       "5         3819 4525 1129 6725 6485 2109 3800 5264 1006 4...\n",
       "6         307 4780 6811 1580 7539 5886 5486 3433 6644 58...\n",
       "7         26 4270 1866 5977 3523 3764 4464 3659 4853 517...\n",
       "8         2708 2218 5915 4559 886 1241 4819 314 4261 166...\n",
       "9         3654 531 1348 29 4553 6722 1474 5099 7541 307 ...\n",
       "10        3659 3659 1903 1866 4326 4744 7239 3479 4261 4...\n",
       "11        6469 1066 1623 1018 3694 4089 3809 4516 6656 3...\n",
       "12        3772 4269 3433 6122 2035 4531 465 6565 498 358...\n",
       "13        4630 2210 1641 1854 1641 4543 3017 4409 5430 6...\n",
       "14        1103 6835 3433 2107 5165 7543 3598 5229 1946 2...\n",
       "15        4412 5988 5036 4216 7539 5644 1906 2380 2252 6...\n",
       "16        2400 4411 5968 2612 6920 4464 3659 6250 2799 5...\n",
       "17        2410 6587 6644 2727 4109 5247 5310 5547 5949 7...\n",
       "18        3170 3508 4163 2974 1952 4417 4987 5505 4163 2...\n",
       "19        4269 3772 5445 2289 2109 5410 1991 5589 2986 1...\n",
       "20        6569 4690 2663 5391 1315 3987 1519 4893 7539 3...\n",
       "21        3017 505 1070 1036 2621 4480 5117 3772 4786 56...\n",
       "22        3263 6104 7539 5744 2827 2367 4893 1647 4315 1...\n",
       "23        3418 1939 220 6886 623 149 1679 3099 1324 7543...\n",
       "24        314 4261 1667 2810 2334 5176 2376 4646 478 132...\n",
       "25        7154 2592 5562 2828 4559 2376 5780 3650 3203 5...\n",
       "26        1965 2717 2728 1951 3744 4831 5698 3915 5099 5...\n",
       "27        6861 6654 1362 4333 3272 1697 7044 1519 4516 4...\n",
       "28        1141 5915 6178 4842 6725 7261 7408 4671 6846 5...\n",
       "29        2289 6357 3577 751 2402 3377 5589 4853 7467 51...\n",
       "                                ...                        \n",
       "249970    23 1405 2109 3695 5834 2820 2891 3000 6324 604...\n",
       "249971    2154 1018 4089 6293 2154 1018 3694 2119 7539 4...\n",
       "249972    2400 150 3770 5036 4981 1519 3223 634 4464 464...\n",
       "249973    2058 2448 3686 3374 908 6986 2465 4679 6832 74...\n",
       "249974    4021 2967 5589 7539 3120 5165 648 1734 3364 72...\n",
       "249975    5096 2539 6045 3530 910 619 6835 5296 5915 364...\n",
       "249976    7507 6122 6615 2328 1726 7010 5598 6609 5510 6...\n",
       "249977    5780 2614 7539 6588 3062 6662 2974 2400 1344 6...\n",
       "249978    3433 790 913 4036 6682 2515 3481 53 913 7445 2...\n",
       "249979    7154 1335 4130 3568 5678 1362 6908 6104 3706 5...\n",
       "249980    1518 1219 3743 4120 7328 4923 7399 5948 4261 6...\n",
       "249981    4516 5521 6985 4166 3272 6832 4936 6308 2465 5...\n",
       "249982    1732 1379 803 7492 2212 4260 1635 2465 2923 91...\n",
       "249983    2109 6350 6308 5450 7539 7346 2563 1242 2331 7...\n",
       "249984    299 2983 3400 7449 465 2255 3263 2465 4646 397...\n",
       "249985    4063 4298 1805 5393 6227 6088 465 2465 6962 53...\n",
       "249986    1141 4411 4151 7400 1914 2304 6596 4531 1334 5...\n",
       "249987    264 6040 3530 4583 5566 5166 2446 902 2483 893...\n",
       "249988    812 382 803 1440 6902 1635 192 2695 2923 1160 ...\n",
       "249989    6065 3370 6482 5397 5681 5724 443 2810 2465 88...\n",
       "249990    5466 1080 1844 4923 3370 6250 4646 3370 2106 2...\n",
       "249991    3501 2722 6248 5620 58 6427 307 2555 3018 7539...\n",
       "249992    7495 5284 2766 7539 5036 2151 6725 100 2465 50...\n",
       "249993    7346 4469 350 6894 3747 4779 5505 544 5780 441...\n",
       "249994    2851 3692 6293 3335 7261 4516 4981 1519 2984 7...\n",
       "249995    3725 4498 2282 1647 6293 4245 4498 3615 1141 2...\n",
       "249996    4811 465 3800 1394 3038 2376 2327 5165 3070 57...\n",
       "249997    5338 1952 3117 4109 299 6656 6654 3792 6831 21...\n",
       "249998    893 3469 5775 584 2490 4223 6569 6663 2124 168...\n",
       "249999    2400 4409 4412 2210 5122 4464 7186 2465 1327 9...\n",
       "Name: text, Length: 250000, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=pd.concat([train['text'],test['text']]).reset_index(drop=True)\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# all_lines = ' '.join(list(texts))\n",
    "# word_count = Counter(all_lines.split(\" \"))\n",
    "# word_count = sorted(word_count.items(), key=lambda d:d[1], reverse = True)\n",
    "# print(len(word_count))\n",
    "# print(word_count[0])\n",
    "# print(word_count[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1),max_features=3000)\n",
    "data_set= vectorizer.fit_transform(texts).toarray()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat=data_set[:200000]\n",
    "test_feat=data_set[200000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.162213\tvalid_1's multi_logloss: 0.236798\n",
      "[200]\ttraining's multi_logloss: 0.0771227\tvalid_1's multi_logloss: 0.193839\n",
      "[300]\ttraining's multi_logloss: 0.0444026\tvalid_1's multi_logloss: 0.184226\n",
      "[400]\ttraining's multi_logloss: 0.0274827\tvalid_1's multi_logloss: 0.182016\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's multi_logloss: 0.0283997\tvalid_1's multi_logloss: 0.182004\n",
      "score: 0.9366422724717209\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(train_feat,train['label'],test_size=0.2,random_state=1)\n",
    "\n",
    "clf=lgb.LGBMClassifier(\n",
    "    n_estimators=700,\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.1,\n",
    "    objective='multiclass',\n",
    "    num_class=14)\n",
    "\n",
    "clf.fit(x_train,y_train,\n",
    "         eval_set=[(x_train,y_train),(x_test,y_test)],\n",
    "         verbose=100,\n",
    "         early_stopping_rounds=100)\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "label=clf.predict(test_feat)\n",
    "score=f1_score(y_test, y_pred, average='macro')\n",
    "print(\"score:\",score)\n",
    "\n",
    "label=pd.DataFrame(label,columns=['label'])\n",
    "label.to_csv(\"lgb_label.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = gensim.models.Word2Vec(texts.values, size=63, iter=10,window=12, min_count=1,\n",
    "                                        workers=8,seed=2020,sample=1e-5,sg=1,hs=1)\n",
    "word2vec_model.save('texts.model')\n",
    "print(\"success!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前 50000 个耗时： 1665.9355807304382\n",
      "前 100000 个耗时： 3205.9941194057465\n",
      "前 150000 个耗时： 4838.847198486328\n",
      "前 200000 个耗时： 6518.758146047592\n",
      "前 50000 个耗时： 1672.5965094566345\n"
     ]
    }
   ],
   "source": [
    "train['text']\n",
    "def Get_vector(trace):    \n",
    "    word2vec_model = gensim.models.Word2Vec.load('texts.model')\n",
    "    index2word_set = set(word2vec_model.wv.index2word)\n",
    "    startTime = time.time()\n",
    "    vector_list = []\n",
    "    num=0\n",
    "    for cutWords in trace:\n",
    "        i=0\n",
    "        article_vector = np.zeros((word2vec_model.trainables.layer1_size))\n",
    "        for cutword in cutWords:\n",
    "            if cutword in index2word_set:\n",
    "                article_vector = np.add(article_vector, word2vec_model.wv[cutword])\n",
    "                i += 1\n",
    "        cutWord_vector = np.divide(article_vector, i)\n",
    "        vector_list.append(list(cutWord_vector))\n",
    "        del cutWord_vector\n",
    "        del article_vector\n",
    "        num+=1\n",
    "        if num %50000==0:\n",
    "            print(\"前\",num,\"个耗时：\",(time.time() - startTime))\n",
    "    return pd.DataFrame(vector_list)\n",
    "train_vector=Get_vector(train['text'].values)\n",
    "test_vector=Get_vector(test['text'].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vector.to_csv(\"train_vec.csv\",index=False)\n",
    "test_vector.to_csv(\"test_vector.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200000x6977 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 56074040 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "\n",
    "word_vectorizer.fit(texts)\n",
    "train_word_features = word_vectorizer.transform(train['text'].values)\n",
    "test_word_features = word_vectorizer.transform(test['text'].values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9484625 0.9218392965754442\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(train_word_features,train['label'],test_size=0.2,random_state=1)\n",
    "clf = LogisticRegression(C=4)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "train_scores = clf.score(x_train, y_train)\n",
    "print(train_scores, f1_score(y_pred, y_test, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=clf.predict(test_word_features)\n",
    "label=pd.DataFrame(label,columns=['label'])\n",
    "label.to_csv(\"label.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's multi_logloss: 0.754206\tvalid_1's multi_logloss: 1.09841\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's multi_logloss: 0.241205\tvalid_1's multi_logloss: 0.320826\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 6977 and input n_features is 63 ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-6b294bb68b85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'macro'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m         result = self.predict_proba(X, raw_score, num_iteration,\n\u001b[1;32m--> 814\u001b[1;33m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    815\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \"\"\"\n\u001b[0;32m    862\u001b[0m         result = super(LGBMClassifier, self).predict(X, raw_score, num_iteration,\n\u001b[1;32m--> 863\u001b[1;33m                                                      pred_leaf, pred_contrib, **kwargs)\n\u001b[0m\u001b[0;32m    864\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_classes\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, raw_score, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    661\u001b[0m                              \u001b[1;34m\"match the input. Model n_features_ is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                              % (self._n_features, n_features))\n\u001b[0m\u001b[0;32m    664\u001b[0m         return self.booster_.predict(X, raw_score=raw_score, num_iteration=num_iteration,\n\u001b[0;32m    665\u001b[0m                                      pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 6977 and input n_features is 63 "
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(train_word_features,train['label'],test_size=0.2,random_state=1)\n",
    "\n",
    "clf=lgb.LGBMClassifier(\n",
    "    n_estimators=700,\n",
    "    boosting_type='gbdt',\n",
    "    learning_rate=0.1,\n",
    "    objective='multiclass',\n",
    "    num_class=14)\n",
    "\n",
    "clf.fit(x_train,y_train,\n",
    "         eval_set=[(x_train,y_train),(x_test,y_test)],\n",
    "         verbose=100,\n",
    "         early_stopping_rounds=100)\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "label=clf.predict(test_vector)\n",
    "score=f1_score(y_test, y_pred, average='macro')\n",
    "print(\"score:\",score)\n",
    "\n",
    "label=pd.DataFrame(label,columns=['label'])\n",
    "label.to_csv(\"lgb_label.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XGBoost-Sklearn",
   "language": "python",
   "name": "xgboost-sklearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
